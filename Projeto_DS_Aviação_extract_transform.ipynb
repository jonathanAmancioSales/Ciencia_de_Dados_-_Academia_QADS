{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEuOLIYGOJI6"
      },
      "source": [
        "# Extração e Transformação\n",
        "Este trabalho faz parte do Projeto Final de Ciência de Dados da Academia QADS.\n",
        "\n",
        "Este notebook comporta as etapas de coleta, transformação e disponibilização (estrutura de datalake) das bases para posterior análise.\n",
        "\n",
        "Destacamos a importância do trabalho de preparação da base final para um menor uso de recursos computacionais e também a criação de novas features, como feriados, valor do dolar mensal, preço médio da passagem e o LF (Load Factor) ou Fator de Ocupação.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgiTcRbBQNAq"
      },
      "source": [
        "# Importacao de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmrYH-o1QQLb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import datetime\n",
        "import requests\n",
        "import urllib.request\n",
        "\n",
        "import holidays\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU0O_-QxQY_a"
      },
      "source": [
        "# Conectar ao Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1WN2ku2pwTF",
        "outputId": "91059902-8f0d-415f-fdb4-d10245de1331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "##################################################\n",
        "from google.colab import drive\n",
        "\n",
        "Drive='/content/gdrive/'\n",
        "drive.mount(Drive)\n",
        "\n",
        "path=Drive+'MyDrive/Projeto_DS/Ambiente_Producao/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRgXZwi0pokJ"
      },
      "source": [
        "# Estrutura Datalake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKBLcFQZptbN"
      },
      "source": [
        "```\n",
        "|\n",
        "|__datalake\n",
        "   |\n",
        "   |___tmp\n",
        "   |   |________tarifa\n",
        "   |   |        |______201601.csv\n",
        "   |   |        |______...\n",
        "   |   |        |______202108.csv\n",
        "   |   |\n",
        "   |   |________basica\n",
        "   |            |______basica2016-01.txt\n",
        "   |            |______...\n",
        "   |            |______basica2021-10.txt\n",
        "   |\n",
        "   |___raw\n",
        "   |   |________tarifa\n",
        "   |   |        |______tarifa_2016.csv\n",
        "   |   |        |______...\n",
        "   |   |        |______tarifa_2021.csv\n",
        "   |   |\n",
        "   |   |________basica\n",
        "   |            |______basica_2016.csv\n",
        "   |            |______...\n",
        "   |            |______basica_2021.csv\n",
        "   |\n",
        "   |___trusted\n",
        "   |   |________tarifa\n",
        "   |   |        |______tarifa_2016.csv\n",
        "   |   |        |______...\n",
        "   |   |        |______tarifa_2021.csv\n",
        "   |   |\n",
        "   |   |________basica\n",
        "   |            |______basica_2016.csv\n",
        "   |            |______...\n",
        "   |            |______basica_2021.csv\n",
        "   |\n",
        "   |___business\n",
        "   |   |________basica_tarifa_dolar_2016.csv\n",
        "   |   |________...\n",
        "   |   |________basica_tarifa_dolar_2021.csv\n",
        "   |   |________basica_tarifa_dolar_completa.csv\n",
        "   |\n",
        "   |___resource\n",
        "       |_______cotacao_mensal.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFGLIWROQSGe"
      },
      "source": [
        "# Funções Úteis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmSMBk5CpwXd"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "# Criar diretorios, caso nao existam:\n",
        "def check_folder(path: str) -> None:\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "# Descompactar todos os arquivos .zip do diretorio informado:\n",
        "def extract_all_zip(path_dir: str, remover=True) -> None:\n",
        "    for file in os.listdir(path_dir):\n",
        "        file = path_dir+file\n",
        "        if file.endswith('.zip'):\n",
        "            try:\n",
        "                with zipfile.ZipFile(file) as z:\n",
        "                    z.extractall(path=path_dir)\n",
        "                # remover arquivos .zip\n",
        "                if remover == True:\n",
        "                    os.remove(file)\n",
        "            except Exception as e:\n",
        "                print(f'Falha ao descompactar arquivo {file}!Erro: {e}')\n",
        "\n",
        "\n",
        "def merge_all(dfs: list) -> pd.DataFrame:\n",
        "    if len(dfs) == 0:\n",
        "        return None\n",
        "    df = dfs[0]\n",
        "    for df2 in dfs[1:]:\n",
        "        #df = df.union(df2)         #pyspark\n",
        "        df = pd.concat([df, df2])   #pandas\n",
        "    return df\n",
        "\n",
        "\n",
        "def ler_bases(padrao: str, path_dir: str) -> pd.DataFrame:\n",
        "    arquivos = [path_dir+arq for arq in os.listdir(path_dir) if padrao in arq]\n",
        "    dfs = []\n",
        "    for arq in arquivos:\n",
        "        df = pd.read_csv(arq, sep=';', encoding='latin-1', low_memory=False)\n",
        "        dfs.append(df)\n",
        "    return merge_all(dfs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zcibw4jLW92"
      },
      "outputs": [],
      "source": [
        "path_datalake = path+'datalake/'\n",
        "check_folder(path_datalake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOjhp6an69Wk"
      },
      "outputs": [],
      "source": [
        "def listar_anos(base: str) -> list:\n",
        "    path_tmp = path_datalake+f'tmp/{base}/'\n",
        "    list_anos = []\n",
        "    for arq in os.listdir(path_tmp):\n",
        "        if base == 'tarifa':\n",
        "            ano = arq[:4]\n",
        "        elif base == 'combinada' or base == 'basica':\n",
        "            ano = arq.replace(base,'').split('-')[0]\n",
        "        else:\n",
        "            raise Exception(f'Base {base} inexistente!')\n",
        "        list_anos.append(ano)\n",
        "    return sorted(list(set(list_anos)))\n",
        "\n",
        "\n",
        "meses = {1:'janeiro',\n",
        "         2:'fevereiro',\n",
        "         3:'marco',\n",
        "         4:'abril',\n",
        "         5:'maio',\n",
        "         6:'junho',\n",
        "         7:'julho',\n",
        "         8:'agosto',\n",
        "         9:'setembro',\n",
        "         10:'outubro',\n",
        "         11:'novembro',\n",
        "         12:'dezembro'}\n",
        "\n",
        "# Meses abreviados:\n",
        "meses_abrv = dict(zip(meses.keys(),[mes[:3].capitalize() for mes in list( meses.values() )]))\n",
        "\n",
        "# Get key by value in dictionary:\n",
        "def get_key_by_value(dictionary: dict, value):\n",
        "    return list(dictionary.keys())[list(dictionary.values()).index(value)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9BcAu2bQlhP"
      },
      "outputs": [],
      "source": [
        "# Feriados\n",
        "def Feriados(Serie, ano: int):\n",
        "    feriados = holidays.Brazil()\n",
        "    feriados = [str(x) for x in feriados[f'{ano}-01-01': f'{ano}-12-31']]\n",
        "\n",
        "    feriados_quinta = [x for x in feriados if pd.to_datetime(x).dayofweek == 3]\n",
        "    feriados_sexta = [x for x in feriados if pd.to_datetime(x).dayofweek == 4]\n",
        "    feriados_segunda = [x for x in feriados if pd.to_datetime(x).dayofweek == 0]\n",
        "    feriados_terca = [x for x in feriados if pd.to_datetime(x).dayofweek == 1]\n",
        "\n",
        "    feriadao = []\n",
        "\n",
        "    for f in feriados_quinta:\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=-1))\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=0))\n",
        "        \n",
        "    for f in feriados_sexta:\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=-1))\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=0))\n",
        "\n",
        "    for f in feriados_segunda:\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=-3))\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=0))\n",
        "\n",
        "    for f in feriados_terca:\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=-4))\n",
        "        feriadao.append(pd.to_datetime(f)+datetime.timedelta(days=0))\n",
        "\n",
        "    feriadao = feriadao + feriados_quinta + feriados_sexta\n",
        "\n",
        "    feriadao = [str(x)[0:10] for x in feriadao]\n",
        "\n",
        "    def if_feriado(x):\n",
        "        if x in feriadao: return 1\n",
        "        else: return 0\n",
        "\n",
        "    return Serie.apply(if_feriado)\n",
        "\n",
        "\n",
        "# Observar os períodos em que há maior fluxo de passageiros em uma série temporal\n",
        "# e criar uma flag para sinalizar esse aumento de fluxo. Testar resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfHqbS2my6-m"
      },
      "source": [
        "# Extração dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uell0uohKt-9"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "def download_file(File: str, servidor: str, path_dir: str) -> None:\n",
        "    try:\n",
        "        urllib.request.urlretrieve(servidor+File, path_dir+File)\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            r = requests.get(servidor+File)\n",
        "            if r.status_code == 200:\n",
        "                with open(path_dir+File, 'wb') as f:\n",
        "                    f.write(r.content)\n",
        "                print(f'Arquivo baixado: {File} -- requests')\n",
        "            else:\n",
        "                print(f\"Falha no download do arquivo {File}!\\nErro: status_code={r.status_code}\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Falha no download do arquivo {File}!\\nErro: {e}\\nErro: {e2}\")\n",
        "\n",
        "\n",
        "def extract(base: str, ano_min: int, ano_max: int) -> None:\n",
        "    path_base = path_datalake+f'tmp/{base}/'\n",
        "    check_folder(path_base)\n",
        "\n",
        "    ####################\n",
        "    if base == 'tarifa':\n",
        "        # Obter lista de links:\n",
        "        url = 'https://sistemas.anac.gov.br/sas/tarifadomestica/'\n",
        "        site = requests.get(url).content\n",
        "        soup = BeautifulSoup(site, 'html.parser')\n",
        "        tag_a_list = soup.find_all('a', href=True)\n",
        "        anos = [a.get('href').split('/')[-2] for a in tag_a_list if re.search('\\d{4}', a.get('href'))!=None]\n",
        "        csv_files = []\n",
        "        for ano in anos:\n",
        "            site = requests.get(url+ano).content\n",
        "            soup = BeautifulSoup(site, 'html.parser')\n",
        "            tag_a_list = soup.find_all('a', href=True)\n",
        "            csv_files += [a.get('href').split('/')[-1] for a in tag_a_list if 'csv' in a.get('href')]\n",
        "\n",
        "        # Download dos dados:\n",
        "        for arq in csv_files:\n",
        "            ano = arq[:4]\n",
        "            if str(ano_min) <= ano <= str(ano_max):\n",
        "                link = url+f'{ano}/'\n",
        "                download_file(File=arq, servidor=link, path_dir=path_base)\n",
        "\n",
        "    ####################\n",
        "    elif base == 'combinada' or base == 'basica':\n",
        "        # Obter lista de links:\n",
        "        url = 'https://www.gov.br/anac/pt-br/assuntos/regulados/empresas-aereas/envio-de-informacoes/microdados/'\n",
        "        site = requests.get(url).content\n",
        "        soup = BeautifulSoup(site, 'html.parser')\n",
        "        tag_a_list = soup.find('table').find_all('a', href=True)\n",
        "        links = [a.get('href') for a in tag_a_list if ('zip' in a.get('href')) and (base in a.get('href'))]\n",
        "\n",
        "        # Download dos dados:\n",
        "        for link in links:\n",
        "            arq = link.split('/')[-1]\n",
        "            ano = arq.replace(base,'').split('-')[0]\n",
        "            link = link.replace(arq, '')\n",
        "            if str(ano_min) <= ano <= str(ano_max):\n",
        "                download_file(File=arq, servidor=link, path_dir=path_base)\n",
        "        extract_all_zip(path_base)\n",
        "\n",
        "    ####################\n",
        "    else:\n",
        "        print(f'Base {base} inexistente!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fBGd6jQLEjR",
        "outputId": "f9fdc91e-3f1e-428b-8fa5-f3450f71623c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 9.87 s, sys: 4.08 s, total: 14 s\n",
            "Wall time: 19min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "extract(base='tarifa', ano_min=2016, ano_max=2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrEgN-oaLEmd",
        "outputId": "56a67442-21c6-407e-91cd-f9d468678b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 28.1 s, sys: 8.87 s, total: 37 s\n",
            "Wall time: 16min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "extract(base='basica', ano_min=2016, ano_max=2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfcGk-4PsEmA",
        "outputId": "b5b799e5-d4ee-482a-c111-46ddaf9b68a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 44.1 s, sys: 16.1 s, total: 1min\n",
            "Wall time: 17min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "extract(base='combinada', ano_min=2016, ano_max=2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoN2EPqdy277"
      },
      "source": [
        "# Transfomacao Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xXfcWXrLEpP"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "## Concatenar dados (Anos) e Salvar dataframe\n",
        "\n",
        "def tranform_raw(base: str) -> None:\n",
        "\n",
        "    path_tmp = path_datalake+f'tmp/{base}/'\n",
        "    path_raw = path_datalake+f'raw/{base}/'\n",
        "    check_folder(path_raw)\n",
        "\n",
        "    list_anos = listar_anos(base)\n",
        "\n",
        "    if base == 'tarifa':\n",
        "        colunas = ['ANO', 'MES', 'EMPRESA', 'ORIGEM', 'DESTINO', 'TARIFA', 'ASSENTOS']\n",
        "        for ano in list_anos:\n",
        "            df = pd.DataFrame({col:[] for col in colunas})\n",
        "            arquivos = [path_tmp+arq for arq in os.listdir(path_tmp) if ano==arq[:4]]\n",
        "            for arq in arquivos:\n",
        "                aux = pd.read_csv(arq, sep=';', encoding='latin-1', decimal=',', low_memory=False)\n",
        "                aux.columns = colunas\n",
        "                df = pd.concat([df, aux])\n",
        "            print(ano, df.shape)\n",
        "            df.to_csv(path_raw+f'{base}_{ano}.csv', sep=';', encoding='latin-1', index=False)\n",
        "    else:\n",
        "        for ano in list_anos:\n",
        "            df = ler_bases(f'{ano}', path_tmp)\n",
        "            print(ano, df.shape)\n",
        "            df.to_csv(path_raw+f'{base}_{ano}.csv', sep=';', encoding='latin-1', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHU9ZO-XLEsG",
        "outputId": "e55cd06f-e6c8-4c06-87cf-547309c90905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (4634293, 7)\n",
            "2017 (4754065, 7)\n",
            "2018 (5113126, 7)\n",
            "2019 (4335164, 7)\n",
            "2020 (3472250, 7)\n",
            "2021 (2661330, 7)\n",
            "CPU times: user 2min 25s, sys: 5.12 s, total: 2min 31s\n",
            "Wall time: 3min 7s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tranform_raw(base='tarifa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Awm8prDAEqA",
        "outputId": "c4a01556-8752-4dd3-cb8f-809e5eb5c9c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (971239, 110)\n",
            "2017 (947583, 110)\n",
            "2018 (974995, 110)\n",
            "2019 (956515, 110)\n",
            "2020 (470845, 110)\n",
            "2021 (469285, 110)\n",
            "CPU times: user 8min 32s, sys: 24 s, total: 8min 56s\n",
            "Wall time: 11min 4s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tranform_raw(base='basica')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myPz1RisAEtw",
        "outputId": "3170a3b0-e831-48f4-e3a1-f358830b97df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (2625277, 90)\n",
            "2017 (2530830, 90)\n",
            "2018 (2405185, 90)\n",
            "2019 (2325077, 90)\n",
            "2020 (1111681, 90)\n",
            "2021 (1054295, 90)\n",
            "CPU times: user 16min 26s, sys: 50.6 s, total: 17min 17s\n",
            "Wall time: 19min 52s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tranform_raw(base='combinada')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD9Z1J6pzCX9"
      },
      "source": [
        "# Transfomacao Trusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDQFDrKNWgEV"
      },
      "outputs": [],
      "source": [
        "def replace_virgula_ponto(v):\n",
        "    if type(v)==str and ',' in v:\n",
        "        return float(v.replace('.','').replace(',','.'))\n",
        "    elif type(v)==str and ',' not in v:\n",
        "        return float(v)\n",
        "    else:\n",
        "        return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXle-vDQLcjg"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "def tranform_trs(base: str) -> None:\n",
        "    path_raw = path_datalake+f'raw/{base}/'\n",
        "    path_trs = path_datalake+f'trusted/{base}/'\n",
        "    check_folder(path_trs)\n",
        "\n",
        "    ######################\n",
        "    if base == 'tarifa':\n",
        "        for ano in listar_anos(base):\n",
        "            df_passagens = ler_bases(ano, path_raw)\n",
        "            #df_passagens = pd.read_csv(path_raw+f'{base}_{ano}.csv', sep=';', encoding='latin-1', low_memory=False)\n",
        "            \n",
        "            # Definir tipos do ano, mes e assentos como inteiro:\n",
        "            df_passagens[['ANO', 'MES', 'ASSENTOS']] = df_passagens[['ANO', 'MES', 'ASSENTOS']].astype('int')\n",
        "\n",
        "            print(ano, df_passagens.shape)\n",
        "            df_passagens['TOTAL'] = df_passagens.TARIFA * df_passagens.ASSENTOS\n",
        "            temp = df_passagens[['ANO', 'MES', 'EMPRESA', 'ORIGEM', 'DESTINO', 'ASSENTOS', 'TOTAL']]\n",
        "\n",
        "            temp = temp.groupby(['ANO', 'MES', 'EMPRESA', 'ORIGEM', 'DESTINO'],as_index=False).agg({'ASSENTOS': 'sum', 'TOTAL': 'sum'})\n",
        "            temp['TICKET_MEDIO'] = round(temp['TOTAL']/temp['ASSENTOS'])\n",
        "            passagens_refined = temp[['ANO','MES','EMPRESA','ORIGEM','DESTINO','TICKET_MEDIO']]\n",
        "            passagens_refined.columns = [cl.lower() for cl in passagens_refined.columns]\n",
        "            passagens_refined.to_csv(path_trs+f'{base}_{ano}.csv', sep=';', encoding='latin-1', index=False)\n",
        "\n",
        "    ######################\n",
        "    elif base == 'basica':\n",
        "        for ano in listar_anos(base):\n",
        "            #for ano in ['2019','2020','2021']:\n",
        "            #df = ler_bases(ano, path_raw)\n",
        "            df = pd.read_csv(path_raw+f'{base}_{ano}.csv', sep=';', encoding='latin-1', low_memory=False)\n",
        "\n",
        "            selecao = [\n",
        "                # features essenciais:\n",
        "                'hr_partida_real', # hora da partida\n",
        "                'hr_chegada_real', # hora da chegada\n",
        "                'ds_grupo_di',\n",
        "                'ds_natureza_tipo_linha',\n",
        "                'ds_natureza_etapa',\n",
        "                'nr_assentos_ofertados',\n",
        "                'dt_referencia', #data\n",
        "                'nr_ano_referencia', # ano\n",
        "                'nr_mes_referencia', # mes\n",
        "                'nr_dia_referencia', # dia\n",
        "                'nm_dia_semana_referencia', # dia da semana\n",
        "                'sg_empresa_icao', # sigla da empresa\n",
        "                'sg_icao_origem', # aeroporto de origem\n",
        "                'sg_icao_destino', # aeroporto de destino\n",
        "                'sg_uf_origem', # uf de origem\n",
        "                'sg_uf_destino', # uf de destino\n",
        "                'nm_regiao_origem',\n",
        "                'nm_regiao_destino',\n",
        "                'nr_horas_voadas',\n",
        "                'nr_passag_gratis',\n",
        "                'kg_peso',\n",
        "                'kg_carga_paga',\n",
        "                'kg_carga_gratis',\n",
        "                'kg_correio',\n",
        "                'km_distancia', # distancia\n",
        "                'sg_equipamento_icao', # aviao\n",
        "                'lt_combustivel', # combustivel\n",
        "                'kg_payload', # peso disponível\n",
        "                'nr_ask', # assentos disponíveis\n",
        "                'nr_rpk',\n",
        "                'nr_atk',\n",
        "                'nr_rtk',\n",
        "                # target:\n",
        "                'nr_passag_pagos']\n",
        "\n",
        "            # Sugestão:\n",
        "            # Criar uma flag para cidades turísticas;\n",
        "            # E talvez uma variável com o n de habitantes da cidade;\n",
        "            \n",
        "            # Selecionar campos de interesse:\n",
        "            df = df[selecao]\n",
        "            print(ano, df.shape, end=' ')\n",
        "\n",
        "            df['nr_horas_voadas'] = df['nr_horas_voadas'].apply(replace_virgula_ponto)\n",
        "            \n",
        "            # Sugestão:\n",
        "            # Criar uma variável com categorias no seguinte formato:\n",
        "            # QUA-10 (10 horas), QUI-12 (12 horas)\n",
        "            # Ou QUA-M (manhã), QUI-T (tarte), DOM-N (noite)\n",
        "\n",
        "            # Criar feature Load Factor:\n",
        "            df['lf_passag'] = df['nr_rpk'].astype(float)/df['nr_ask'].astype(float)\n",
        "            df['lf_peso'] = df['nr_rtk'].astype(float)/df['nr_atk'].astype(float)\n",
        "\n",
        "            # Criar feature rendimento do combustível:\n",
        "            df['rend_combustivel'] = round(df['km_distancia'].astype(float)/df['lt_combustivel'].astype(float),4)\n",
        "\n",
        "            # Reduzir nome do dia da semana:\n",
        "            def reduzir(s):\n",
        "                return re.sub('SÁB','SAB', s[0:3])\n",
        "            df.nm_dia_semana_referencia = df.nm_dia_semana_referencia.apply(reduzir)\n",
        "\n",
        "            def get_hora(h):\n",
        "                try:\n",
        "                    return h.split(':')[0]\n",
        "                except:\n",
        "                    return None\n",
        "\n",
        "            df['hora'] = df['hr_partida_real'].apply(get_hora)\n",
        "\n",
        "            # Aplicar varios filtros:\n",
        "            df = df[ (df.ds_grupo_di=='REGULAR') &\n",
        "                     (df.ds_natureza_tipo_linha=='DOMÉSTICA') &\n",
        "                     (df.ds_natureza_etapa=='DOMÉSTICA') &\n",
        "                     (df.nr_assentos_ofertados > 0) ]\n",
        "\n",
        "            # Adicionar flag de feriados:\n",
        "            df['feriadao'] = Feriados(df['dt_referencia'], ano)\n",
        "\n",
        "            # Converter colunas para int:\n",
        "            colunas_int = ['kg_peso', 'kg_carga_paga', 'kg_carga_gratis', 'kg_correio',\n",
        "                           'nr_passag_gratis', 'nr_passag_pagos', 'km_distancia', 'lt_combustivel']\n",
        "  \n",
        "            def convert_int(x):\n",
        "                try:\n",
        "                    return int(x)\n",
        "                except:\n",
        "                    return x\n",
        "\n",
        "            for c in colunas_int:\n",
        "                #df[c] = df[c].astype(int)\n",
        "                df[c] = df[c].apply(convert_int)\n",
        "\n",
        "            print(df.shape)\n",
        "            df.to_csv(path_trs+f'{base}_{ano}.csv', sep=';', encoding='latin-1', index=False)\n",
        "\n",
        "    ######################\n",
        "    else:\n",
        "        print(f'Base {base} inexistente!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOLRGWSDS7lF",
        "outputId": "e08afb37-a09a-485b-839d-dd1841e2fe4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (971239, 33) (776189, 38)\n",
            "2017 (947583, 33) (752746, 38)\n",
            "2018 (974995, 33) (778618, 38)\n",
            "2019 (956515, 33) (758789, 38)\n",
            "2020 (470845, 33) (369526, 38)\n",
            "2021 (469285, 33) (394358, 38)\n",
            "CPU times: user 3min 58s, sys: 20.8 s, total: 4min 18s\n",
            "Wall time: 4min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tranform_trs('basica')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkEOrUJ7LDTG",
        "outputId": "8df2f73e-4f2e-4987-fc89-3706fc7ee9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (4634293, 7)\n",
            "2017 (4754065, 7)\n",
            "2018 (5113126, 7)\n",
            "2019 (4335164, 7)\n",
            "2020 (3472250, 7)\n",
            "2021 (2661330, 7)\n",
            "CPU times: user 25.4 s, sys: 2.25 s, total: 27.7 s\n",
            "Wall time: 29.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tranform_trs('tarifa')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7nM0u-My0W"
      },
      "source": [
        "# Transfomacao Business"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUnF30WqD80K"
      },
      "outputs": [],
      "source": [
        "def editar_mes_ano(m_a) -> str:\n",
        "    m,a = m_a.split()\n",
        "    m = get_key_by_value(dictionary=meses_abrv, value=m)\n",
        "    m = str(m).zfill(2)\n",
        "    a = str(2000+int(a))\n",
        "    return f'{a}-{m}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HGavUZoLcf-"
      },
      "outputs": [],
      "source": [
        "def tranform_bis() -> None:\n",
        "    path_trs = path_datalake+'trusted/'\n",
        "    path_bis = path_datalake+'business/'\n",
        "    check_folder(path_bis)\n",
        "\n",
        "    for ano in listar_anos('basica'):\n",
        "        df_basica = pd.read_csv(path_trs+f'basica/basica_{ano}.csv', sep=';', encoding='latin-1', low_memory=False)\n",
        "        df_tarifa = pd.read_csv(path_trs+f'tarifa/tarifa_{ano}.csv', sep=';', encoding='latin-1', low_memory=False)\n",
        "\n",
        "        df_basica_tarifa = pd.merge(df_basica, df_tarifa,\n",
        "                                    left_on=['nr_ano_referencia', # ano\n",
        "                                             'nr_mes_referencia', # mes\n",
        "                                             'sg_empresa_icao', # empresa\n",
        "                                             'sg_icao_origem', # origem\n",
        "                                             'sg_icao_destino' # destino\n",
        "                                             ],\n",
        "                                    right_on=['ano', 'mes', 'empresa', 'origem', 'destino'])\n",
        "\n",
        "        print(ano, df_basica_tarifa.shape, end=' ')\n",
        "\n",
        "        #####################################\n",
        "        cotacoes = pd.read_csv(path_datalake+'resource/'+'cotacao_mensal.csv', decimal=',')[['Data','Último']]\n",
        "        cotacoes.columns = ['mes_abrv_ano_abrv','dolar']\n",
        "\n",
        "        cotacoes['ano_mes'] = cotacoes['mes_abrv_ano_abrv'].apply(editar_mes_ano)\n",
        "        cotacoes.drop(columns='mes_abrv_ano_abrv', inplace=True)\n",
        "        #####################################\n",
        "\n",
        "        df_basica_tarifa['ano_mes'] = df_basica_tarifa['dt_referencia'].apply(lambda x: str(x)[0:7])\n",
        "        df_final = pd.merge(df_basica_tarifa, cotacoes, left_on='ano_mes', right_on='ano_mes')\n",
        "\n",
        "        df_final.columns = [re.sub('_referencia', '', cl) for cl in df_final.columns]\n",
        "\n",
        "        # Selecionar campos de interesse:\n",
        "        selecao = ['dt', 'nr_ano', 'nr_mes', 'nr_dia', 'nm_dia_semana', 'sg_empresa_icao',\n",
        "                   'hr_partida_real', 'hr_chegada_real', 'sg_icao_origem',\n",
        "                   'sg_icao_destino', 'nm_regiao_origem', 'nm_regiao_destino',\n",
        "                   'sg_uf_origem', 'sg_uf_destino', 'sg_equipamento_icao', 'km_distancia',\n",
        "                   'nr_horas_voadas', 'lt_combustivel', 'nr_assentos_ofertados',\n",
        "                   'nr_passag_pagos', 'nr_passag_gratis', 'kg_payload', 'kg_peso',\n",
        "                   'kg_carga_paga', 'kg_carga_gratis', 'kg_correio', 'nr_ask', 'nr_rpk',\n",
        "                   'nr_atk', 'nr_rtk', 'lf_passag', 'lf_peso', 'rend_combustivel',\n",
        "                   'dolar', 'ticket_medio']\n",
        "        df_final = df_final[selecao]\n",
        "\n",
        "        print(df_final.shape)\n",
        "        df_final.to_csv(path_bis+f'basica_passagem_dolar_{ano}.csv', sep=';', encoding='latin-1', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUKL9Ynm-1GJ",
        "outputId": "9f93c09e-47ff-4298-a302-16da50dd013b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016 (774905, 44) (774905, 35)\n",
            "2017 (751364, 44) (751364, 35)\n",
            "2018 (776216, 44) (776216, 35)\n",
            "2019 (746763, 44) (746763, 35)\n",
            "2020 (353811, 44) (353811, 35)\n",
            "2021 (283202, 44) (283202, 35)\n"
          ]
        }
      ],
      "source": [
        "tranform_bis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9qkDe18GTZ5",
        "outputId": "5d4c047a-2e56-48d6-83a2-082d228fd59c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 36s, sys: 5.06 s, total: 1min 41s\n",
            "Wall time: 1min 47s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Concatenar bases (todos os anos):\n",
        "path_bis = path_datalake+f'business/'\n",
        "\n",
        "df = ler_bases('basica', path_bis)\n",
        "df.to_csv(path_bis+f'basica_passagem_dolar_completa_2016-2021.csv', sep=';', encoding='latin-1', index=False)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "HvSEMyoQv4c-",
        "outputId": "e1841b60-1a31-4095-9716-acea9a0069b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>nr_ano</th>\n",
              "      <th>nr_mes</th>\n",
              "      <th>nr_dia</th>\n",
              "      <th>nm_dia_semana</th>\n",
              "      <th>sg_empresa_icao</th>\n",
              "      <th>hr_partida_real</th>\n",
              "      <th>hr_chegada_real</th>\n",
              "      <th>sg_icao_origem</th>\n",
              "      <th>sg_icao_destino</th>\n",
              "      <th>nm_regiao_origem</th>\n",
              "      <th>nm_regiao_destino</th>\n",
              "      <th>sg_uf_origem</th>\n",
              "      <th>sg_uf_destino</th>\n",
              "      <th>sg_equipamento_icao</th>\n",
              "      <th>km_distancia</th>\n",
              "      <th>nr_horas_voadas</th>\n",
              "      <th>lt_combustivel</th>\n",
              "      <th>nr_assentos_ofertados</th>\n",
              "      <th>nr_passag_pagos</th>\n",
              "      <th>nr_passag_gratis</th>\n",
              "      <th>kg_payload</th>\n",
              "      <th>kg_peso</th>\n",
              "      <th>kg_carga_paga</th>\n",
              "      <th>kg_carga_gratis</th>\n",
              "      <th>kg_correio</th>\n",
              "      <th>nr_ask</th>\n",
              "      <th>nr_rpk</th>\n",
              "      <th>nr_atk</th>\n",
              "      <th>nr_rtk</th>\n",
              "      <th>lf_passag</th>\n",
              "      <th>lf_peso</th>\n",
              "      <th>rend_combustivel</th>\n",
              "      <th>dolar</th>\n",
              "      <th>ticket_medio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324084</th>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>2016</td>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>DOM</td>\n",
              "      <td>TAM</td>\n",
              "      <td>21:42:00</td>\n",
              "      <td>23:04:00</td>\n",
              "      <td>SBSP</td>\n",
              "      <td>SBUL</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SP</td>\n",
              "      <td>MG</td>\n",
              "      <td>A320</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1.37</td>\n",
              "      <td>3824</td>\n",
              "      <td>174</td>\n",
              "      <td>114</td>\n",
              "      <td>3</td>\n",
              "      <td>16900</td>\n",
              "      <td>10200</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>96048.0</td>\n",
              "      <td>62928.0</td>\n",
              "      <td>9328.0</td>\n",
              "      <td>5506.0</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.590266</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>3.6105</td>\n",
              "      <td>231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383251</th>\n",
              "      <td>2018-07-31</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>TER</td>\n",
              "      <td>AZU</td>\n",
              "      <td>11:14:00</td>\n",
              "      <td>12:46:00</td>\n",
              "      <td>SBFN</td>\n",
              "      <td>SBRF</td>\n",
              "      <td>NORDESTE</td>\n",
              "      <td>NORDESTE</td>\n",
              "      <td>PE</td>\n",
              "      <td>PE</td>\n",
              "      <td>AT72</td>\n",
              "      <td>549.0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>1216</td>\n",
              "      <td>70</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>6970</td>\n",
              "      <td>5817</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38430.0</td>\n",
              "      <td>37881.0</td>\n",
              "      <td>3826.0</td>\n",
              "      <td>3152.0</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>0.823837</td>\n",
              "      <td>0.4515</td>\n",
              "      <td>3.7557</td>\n",
              "      <td>384.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225472</th>\n",
              "      <td>2019-04-13</td>\n",
              "      <td>2019</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>SAB</td>\n",
              "      <td>AZU</td>\n",
              "      <td>06:24:00</td>\n",
              "      <td>08:39:00</td>\n",
              "      <td>SBCF</td>\n",
              "      <td>SBFI</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SUL</td>\n",
              "      <td>MG</td>\n",
              "      <td>PR</td>\n",
              "      <td>E195</td>\n",
              "      <td>1267.0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>5809</td>\n",
              "      <td>118</td>\n",
              "      <td>107</td>\n",
              "      <td>7</td>\n",
              "      <td>10745</td>\n",
              "      <td>9385</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>149506.0</td>\n",
              "      <td>135569.0</td>\n",
              "      <td>13613.0</td>\n",
              "      <td>11225.0</td>\n",
              "      <td>0.906780</td>\n",
              "      <td>0.824579</td>\n",
              "      <td>0.2181</td>\n",
              "      <td>3.9207</td>\n",
              "      <td>450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382719</th>\n",
              "      <td>2018-07-06</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>SEX</td>\n",
              "      <td>AZU</td>\n",
              "      <td>18:55:00</td>\n",
              "      <td>20:09:00</td>\n",
              "      <td>SBRJ</td>\n",
              "      <td>SBKP</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>RJ</td>\n",
              "      <td>SP</td>\n",
              "      <td>E190</td>\n",
              "      <td>407.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2665</td>\n",
              "      <td>106</td>\n",
              "      <td>51</td>\n",
              "      <td>7</td>\n",
              "      <td>11330</td>\n",
              "      <td>4706</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43142.0</td>\n",
              "      <td>20757.0</td>\n",
              "      <td>4611.0</td>\n",
              "      <td>1701.0</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.368900</td>\n",
              "      <td>0.1527</td>\n",
              "      <td>3.7557</td>\n",
              "      <td>420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196622</th>\n",
              "      <td>2017-04-19</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>QUA</td>\n",
              "      <td>AZU</td>\n",
              "      <td>05:53:00</td>\n",
              "      <td>07:01:00</td>\n",
              "      <td>SBGR</td>\n",
              "      <td>SBCF</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SUDESTE</td>\n",
              "      <td>SP</td>\n",
              "      <td>MG</td>\n",
              "      <td>E195</td>\n",
              "      <td>497.0</td>\n",
              "      <td>1.13</td>\n",
              "      <td>2575</td>\n",
              "      <td>118</td>\n",
              "      <td>109</td>\n",
              "      <td>1</td>\n",
              "      <td>12548</td>\n",
              "      <td>9510</td>\n",
              "      <td>484</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58646.0</td>\n",
              "      <td>54173.0</td>\n",
              "      <td>6236.0</td>\n",
              "      <td>4689.0</td>\n",
              "      <td>0.923729</td>\n",
              "      <td>0.751924</td>\n",
              "      <td>0.1930</td>\n",
              "      <td>3.1758</td>\n",
              "      <td>214.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                dt  nr_ano  nr_mes  ...  rend_combustivel   dolar ticket_medio\n",
              "324084  2016-05-22    2016       5  ...            0.1444  3.6105        231.0\n",
              "383251  2018-07-31    2018       7  ...            0.4515  3.7557        384.0\n",
              "225472  2019-04-13    2019       4  ...            0.2181  3.9207        450.0\n",
              "382719  2018-07-06    2018       7  ...            0.1527  3.7557        420.0\n",
              "196622  2017-04-19    2017       4  ...            0.1930  3.1758        214.0\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw8YEQsNnKhF"
      },
      "source": [
        "_______________"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NgiTcRbBQNAq",
        "PU0O_-QxQY_a",
        "nRgXZwi0pokJ",
        "xFGLIWROQSGe",
        "XfHqbS2my6-m",
        "LoN2EPqdy277",
        "FD9Z1J6pzCX9",
        "Xd7nM0u-My0W"
      ],
      "name": "Projeto DS Aviação - extract_transform+.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}